import pandas as pd
from sklearn.preprocessing import StandardScaler
from itertools import combinations
import math
from matplotlib import pyplot as plt
import numpy as np
from numpy import percentile
import random
from statistics import variance as var


class baseHeuristic:
    def __init__(self,df):
        
        #df = input dataframe ==> first column must be text identifier, the rest must be numeric
        #distCalc = Type of distance calculation to be used ==> 'euc' = Euclidean, 'man' = Manhattan, 'cos' = cosine
        #aggrMethod = list as long as the columns of df-1, that dictates what kind of aggregation should be done
        #             on a group level ==> 'sum' = add columns by group, 'avg' = get average of columns by group
        
        
        #user input parameters
        self.df = df

        #method created parameters
        self.stdDf = None
        self.aggrDf = None

        #simple calculated parameters
        self.df_len = len(df)
        self.col_ct = len(df.columns)
        self.col_types = self.df.dtypes

        #data validation for df input (dataframe check)
        if isinstance(self.df, pd.DataFrame) == False:
            raise Exception("Input Error: Parameter df must be a pandas dataframe")

        #data validation for df input (check that first column is char and all others are numeric)

        #data validation for distCalc input
        #if self.distCalc not in ['euc','man','cos']:
            #raise Exception("Input Error: Parameter distCalc must be 'euc','man', or 'cos'.")
    
    
        #create a standardized data set when the instance is created
        temp_df = self.df.iloc[:,1:self.col_ct]
        scaler = StandardScaler()
        scaler = scaler.fit_transform(temp_df)
        temp_df = pd.DataFrame(scaler)
        
        #combine standardized data back to label column
        self.stdDf = pd.concat([self.df.iloc[:,0],temp_df],axis=1)
 
    
    def varSizeStartSol(self):
        
        grouping = []
        
        #create label list to hold all lables 
        label_list = list(self.df.iloc[:,0]) 
  
        #initiate first element in each group
        for i in range(0,self.numGroups):
            rand_num = random.randint(0,len(label_list)-1)
            grouping.append([label_list[rand_num]])
            label_list.pop(rand_num) 
            
        while len(label_list) > 0:
            
            rand_group = random.randint(0,self.numGroups-1)
            rand_num = random.randint(0,len(label_list)-1)
            grouping[rand_group].append(label_list[rand_num])
            label_list.pop(rand_num)             
            
        return grouping
        
        
        #method to create starting solution
    def startSol(self,randStart='Y',startMetric=1,seed=1920):
        
        #conditionally create a random or deterministic starting solution
        if randStart == 'Y':
            
            #set random seed
            #random.seed(seed)
            
            #create label list to hold all lables 
            label_list = list(self.df.iloc[:,0])
            
            #instantiate grouping list
            grouping = []

            #initiate first element in each group
            for i in range(0,self.numGroups):
                rand_num = random.randint(0,len(label_list)-1)
                grouping.append([label_list[rand_num]])
                label_list.pop(rand_num)
                
            #loop through each group and add a random element to it until no more elements are left
            while len(label_list) > 1:
                for j in range(0,self.numGroups):
                    #exit loop if label_list becomes too short to avoid out of range errors generated by rand_num
                    if len(label_list) == 1:
                        break
                    rand_num = random.randint(0,len(label_list)-1)
                    grouping[j].append(label_list[rand_num])
                    label_list.pop(rand_num)
                    temp_j = j
            
            #put the last remaining value to the grouping
            grouping[temp_j + 1].append(label_list[0])
                    
                             
        #if not a random starting place, 
        elif randStart == 'N':
            #sort dataframe by startMetric column
            sorted_df = self.df.sort_values(self.startMetric)

            #convert label column in df to list to access .pop() method
            label_list = list(sorted_df.iloc[:,0])
            
            
            #put each element recursively in a group
            grouping = []
            #manually do first iteration to instantiate the appropriate sized list
            for h in range(0,self.numGroups):
                grouping.append([label_list[h]])
            
            #remove elements that were added to grouping in the previous loop
            label_list = label_list[self.numGroups:len(label_list)]

                
            #now that the grouping list is instantiated w/ approprate dimensions, put the rest of the elements into groups
            switch_dir = 1
            
            while len(label_list) > 0:
                if switch_dir == 0:
                
                    #create a varable for looping based on length of lable_list and self.numGroups
                    if len(label_list) < self.numGroups:
                        loop_count = len(label_list)
                    else:
                        loop_count = self.numGroups
                    
                    
                    for i in range(0,loop_count):
                        
                        grouping[i].append(label_list[i])
                        
                    #remove all elements that were just added to the grouping list
                    label_list = label_list[loop_count:len(label_list)]
                            
                    #set switch_dir to 1, so it will loop the opposite direction next while iteration
                    switch_dir = 1
                    print(grouping)
                    
                elif switch_dir == 1:

                    
                    for j in range(self.numGroups-1,-1,-1):
                        print(j)
                        
                        #exit loops if label_list is empty
                        if len(label_list) == 0:
                            break
                            
                        grouping[j].append(label_list[0])
                        label_list.pop(0)
                    
                    
                    #set switch_dir to 0, so it will loop the opposite direction next while iteration
                    switch_dir = 0
                    print(grouping)
        return grouping
    
    
    #standardize elements in df
    def standardize(self):
        
        temp_df = self.df.iloc[:,1:self.col_ct]
        scaler = StandardScaler()
        scaler = scaler.fit_transform(temp_df)
        temp_df = pd.DataFrame(scaler)
        
        #combine standardized data back to label column
        self.stdDf = pd.concat([self.df.iloc[:,0],temp_df],axis=1)
        
        return self.stdDf
            
        
    #calculate distance between just two records
    def pairDist(self,a,b,distCalc,):
        
        #convert pandas series to list
        if isinstance(a,pd.core.series.Series) == True:
            a = a.tolist()
        if isinstance(b,pd.core.series.Series) == True:
            b = b.tolist()
        
        #set up variables for the execution of the calculation
        list_len = len(a)
        dist_sum = 0
        temp_dist = 0
        
        #calculate distance based on user self.distCalc (exclude first element in list)
        #Euclidean distance
        if distCalc == 'euc':
            
            for i in range(0,list_len):
                
                temp_dist = (a[i]-b[i])**2
                dist_sum = dist_sum + temp_dist
                
            euc_dist = math.sqrt(dist_sum)
            return euc_dist
                
        #manhattan distance    
        elif distCalc == 'man':
            
            for i in range(1,list_len):
                temp_dist = abs(a[i]-b[i])
                dist_sum = dist_sum + temp_dist
            
            man_dist = dist_sum
            
            return man_dist
        
        #cosine distance
        elif distCalc == 'cos':
            
            #convert to np array
            a = np.asarray(a[:][1:])
            b = np.asarray(b[:][1:])
            
            #calculate dot product
            dot_prod = np.dot(a,b)
            
            #calculate magnitudes
            a_mag = np.linalg.norm(a)
            b_mag = np.linalg.norm(b)
            
            #calculate cosine distance
            cos_dist = dot_prod/(a_mag*b_mag)
            
            return cos_dist
    
    #calculate aggregated metrics by input groups
    def groupMetrics(self,groups,aggMethod):
        #Instantiate master list to hold aggregated metrics by group
        master_list = []
        
        #iterate through all groups -- groups will come from the hueristic portion of the programming
        for i in range(0,len(groups)):
            temp_group = groups[i]
            temp_df = self.stdDf[self.stdDf.iloc[:,0].isin(temp_group)]

            #start temp_list with group number
            temp_list = [i]
            #iterate through columns at a group level
            for j in range(0,(len(self.stdDf.columns)-1)):

                #if user input list of aggregation types is 'sum', then execute
                if aggMethod == 'sum':
                    #calculate column sum
                    temp_aggr = temp_df.iloc[:,j+1].sum()
                    #append summed value to list
                    temp_list.append(temp_aggr)

                #if user input list of aggregation types is 'avg', then execute
                elif aggMethod == 'avg':
                    #calculate column mean
                    temp_aggr = temp_df.iloc[:,j+1].mean()
                    #append mean value to list
                    temp_list.append(temp_aggr)
                #put temp_list in master_list once all columns for the group have been aggregated
            master_list.append(temp_list)

            #convert master list into dataframe
            master_df = pd.DataFrame(master_list)
            
            #set self.aggrDf attribute equal to the aggregated group dataframe
            self.aggrDf = master_df
        
            
        return master_df

    #add up all of the pairwise distances using pairDist method
    def totalDist(self,groups,dist,varFactor=36.85):
        
        row_num = len(groups)
        combins = list(combinations(list(range(0,row_num)),2))

        #instantiate variable to hold total distance
        total_dist = 0
        
        dist_list = []
        
        for i in range(0,len(combins)):

            temp_dist_df = groups[groups.iloc[:,0].isin(combins[i])]
            
            #Get pairwise distance between two groups at a time, using self.pairDist
            
            temp_dist = self.pairDist(temp_dist_df.iloc[0][1:],temp_dist_df.iloc[1][1:],dist)
            
            dist_list.append(temp_dist)
            
            #add to total_dist
            total_dist = total_dist + temp_dist
            
        dist_var = var(dist_list)
        
        total_dist = total_dist + varFactor*dist_var
        
        return total_dist
    
    
    #create a function to make a histogram of random position values
    def sample_hist(self,sample_size,bin_count,aggMethod,distMetric,sample_type='equal size',varFactor=36.85):
        
        sample_dists = []
        
        if sample_type == 'equal size':
            
            print('Starting samples of solution space')
            for i in range(0,sample_size):
                temp_solution = self.startSol()
                
                temp_dist = self.totalDist(self.groupMetrics(temp_solution,aggMethod),distMetric,varFactor=varFactor)
            
                sample_dists.append(temp_dist)
                

        
        elif sample_type == 'var size':
            
            for i in range(0,sample_size):
                temp_solution = self.varSizeStartSol()
                
                temp_dist = self.totalDist(self.groupMetrics(temp_solution,aggMethod),distMetric)
            
                sample_dists.append(temp_dist)        
        
        print('making histogram')
        sample_dists_np = np.array(sample_dists)
        plt.hist(sample_dists_np.flatten(),bins=bin_count)
        plt.xticks(np.arange(0,80,5),rotation='vertical')    
        plt.show()
        
        #convert to numpy array
        print('convert to df and pickle')
        sample_dists_np = np.array(sample_dists)
        
        sample_dists_df = pd.DataFrame(sample_dists_np)
        
        sample_dists_df.to_pickle("./sample_distribution.pkl")

        quartiles = percentile(sample_dists_np, [25,50,75])
        data_min, data_max = sample_dists_np.min(), sample_dists_np.max()
        
        five_num_summary = [data_min,quartiles[0],quartiles[1],quartiles[2],data_max]
        
        print(five_num_summary)
        
        
        
        return [five_num_summary, sample_dists]
    
    
    #add up all of the pairwise distances using pairDist method



    def totalDistAndVar(self,groups,dist,varFactor=0):


        row_num = len(groups)
        combins = list(combinations(list(range(0,row_num)),2))

        #instantiate variable to hold total distance
        total_dist = 0

        dist_list = []

        for i in range(0,len(combins)):

            temp_dist_df = groups[groups.iloc[:,0].isin(combins[i])]

            #Get pairwise distance between two groups at a time, using self.pairDist


            temp_dist = self.pairDist(temp_dist_df.iloc[0][1:],temp_dist_df.iloc[1][1:],dist)

            dist_list.append(temp_dist)


            #add to total_dist
            total_dist = total_dist + temp_dist


        dist_var = var(dist_list)

        total_dist = total_dist + varFactor*dist_var


        return dist_var, total_dist


    #make a histogram of variables
    def sample_hist_var(self,sample_size,bin_count,aggMethod,distMetric,sample_type='equal size',varFactor=0):


        sample_vars = []

        if sample_type == 'equal size':

            print('Starting samples of solution space')

            for i in range(0,sample_size):

                temp_solution = self.startSol()


                temp_var, temp_dist = self.totalDistAndVar(self.groupMetrics(temp_solution,aggMethod),distMetric,varFactor=varFactor)


                sample_vars.append(math.log(temp_var**2))


        elif sample_type == 'var size':


            for i in range(0,sample_size):

                temp_solution = self.varSizeStartSol()
                temp_var, temp_dist = self.totalDistAndVar(self.groupMetrics(temp_solution,aggMethod),distMetric)
                sample_vars.append(temp_var)        

        print('making histogram')
        
        sample_vars_np = np.array(sample_vars)

        plt.hist(sample_vars_np.flatten(),bins=bin_count)
        plt.xticks(np.arange(0,5,0.25),rotation='vertical')   

        plt.show()

        #convert to numpy array

        print('convert to df and pickle')
        


        sample_vars_df = pd.DataFrame(sample_vars_np)

        sample_vars_df.to_pickle("./sample_var_distribution.pkl")

        quartiles = percentile(sample_vars_np, [25,50,75])
        
        data_min, data_max = sample_vars_np.min(), sample_vars_np.max()


        five_num_summary = [data_min,quartiles[0],quartiles[1],quartiles[2],data_max]

        print(five_num_summary)

        return [five_num_summary, sample_vars]    
    
    
import nbr_hood as nbr
import random
import pandas as pd
import numpy as np

#create class for hill climb algorithms
class hillClimb(nbr.nbrHood):
    
    def __init__(self,df,numGroups,nbrhoodsize):
        
        super().__init__(df,numGroups)
        self.nbrhoodsize = nbrhoodsize
        
    
    def runHillClimb(self,selectMethod,restarts,aggMethod,distMetric,startMetric=1,randStart='Y',seed=1920,power=1):
        #start random seed
        
        #random.seed(seed)
        obs = 0
        
        #create a starting solution
        startSolution = self.startSol(randStart=randStart,startMetric=startMetric)
        
        #conditionally execute hill climb with best accept
        if selectMethod == 'BEST ACCEPT':
        
            globalBestNbr = startSolution
            globalBestDist = self.totalDist(self.groupMetrics(startSolution,aggMethod),distMetric)
            
            for j in range(0,restarts):
                
                #do a random start if it is not the first iteration
                if j == 0:
                    currentSolution = startSolution
                else:
                    currentSolution = self.startSol(randStart=randStart,startMetric=startMetric)
            
                done = 0
            
                while done == 0:
                    
                    bestNbr = currentSolution
                    bestDist = self.totalDist(self.groupMetrics(currentSolution,aggMethod),distMetric)
                    
                    for i in self.createNbrhood(currentSolution,self.nbrhoodsize):
                        obs = obs + 1
                        if self.totalDist(self.groupMetrics(i,aggMethod),distMetric) < self.totalDist(self.groupMetrics(bestNbr,aggMethod),distMetric):
                            bestNbr = i
                            bestDist = self.totalDist(self.groupMetrics(i,aggMethod),distMetric)
                            print(bestDist)
                            
                    if currentSolution == bestNbr:
                        done = 1
                    else:
                        currentSolution = bestNbr 
                        
                        
                print("restart")
                
                if bestDist < globalBestDist:
                    globalBestNbr = bestNbr
                    globalBestDist = self.totalDist(self.groupMetrics(bestNbr,aggMethod),distMetric)
                    print("New Global Best = %s" % globalBestDist)
                    
                    
            #put the globals back into the locals so the return statement returns the global bests
            #bestNbr = globalBestNbr
            #bestDist = globalBestDist
            
            print("done")        
        

        
        #implement first accept method
        elif selectMethod == 'HILL CLIMB':
            
            for j in range(0,restarts):
                
                #do a random start if it is not the first iteration
                if j == 0:
                    currentSolution = startSolution
                else:
                    currentSolution = self.startSol(randStart=randStart,startMetric=startMetric)
            
            done = 0
            
            while done == 0:
                
                bestNbr = currentSolution
                bestDist = self.totalDist(self.groupMetrics(currentSolution,aggMethod),distMetric)
                
                for i in self.createNbrhood(currentSolution,self.nbrhoodsize):
                    obs = obs + 1
                    if self.totalDist(self.groupMetrics(i,aggMethod),distMetric) < self.totalDist(self.groupMetrics(bestNbr,aggMethod),distMetric):
                        bestNbr = i
                        bestDist = self.totalDist(self.groupMetrics(i,aggMethod),distMetric)
                        print(bestDist)
                        
                if currentSolution == bestNbr:
                    done = 1
                else:
                    currentSolution = bestNbr
                    
        
        
        elif selectMethod == 'FIRST ACCEPT':
            
            globalBestNbr = startSolution
            globalBestDist = self.totalDist(self.groupMetrics(startSolution,aggMethod),distMetric)
            
            for j in range(0,restarts):
                

                    
                #do a random start if it is not the first iteration
                if j == 0:
                    currentSolution = startSolution
                else:
                    currentSolution = self.startSol(randStart=randStart,startMetric=startMetric)
                        
                print(currentSolution)
            
                done = 0
            
                while done == 0:
                    
                    bestNbr = currentSolution
                    
                    bestDist = self.totalDist(self.groupMetrics(currentSolution,aggMethod),distMetric)
                    

                    for i in self.createNbrhood(currentSolution,self.nbrhoodsize):
                        
                        
                        obs = obs + 1
                        if self.totalDist(self.groupMetrics(i,aggMethod),distMetric) < self.totalDist(self.groupMetrics(bestNbr,aggMethod),distMetric):
                            bestNbr = i
                            bestDist = self.totalDist(self.groupMetrics(i,aggMethod),distMetric)
                            print(bestDist)
                            #add break to make it first accept
                            break
                            
                    if currentSolution == bestNbr:
                        done = 1
                    else:
                        currentSolution = bestNbr 
                        
                        
                print("restart")
                
                if bestDist < globalBestDist:
                    globalBestNbr = bestNbr
                    globalBestDist = self.totalDist(self.groupMetrics(bestNbr,aggMethod),distMetric)
                    print("New Global Best = %s" % globalBestDist)
                    
                    
            #put the globals back into the locals so the return statement returns the global bests
            #bestNbr = globalBestNbr
            #bestDist = globalBestDist
            
            print("done")
            
        #conditionally execute random walk with best accept
        
        #I haven't actually coded the random walk yet.  Below is just Best Accept.
        #make necessary changes to make below code random walk.
        if selectMethod == 'RANDOM WALK':
            
            #create method to find random walked solution
            def rand_find(prob_list,rand_num):
                
                pos = -1
                
                for i in prob_list:
                    pos = pos + 1
                    if i > rand_num:
                        return pos            
        
            globalBestNbr = startSolution
            globalBestDist = self.totalDist(self.groupMetrics(startSolution,aggMethod),distMetric)
            
            for j in range(0,restarts):
                
                #do a random start if it is not the first iteration
                if j == 0:
                    currentSolution = startSolution
                else:
                    currentSolution = self.startSol(randStart=randStart,startMetric=startMetric)            
            
                done = 0
            
                while done == 0:
                    
                    temp_nbr_df = pd.DataFrame(columns=['nbr','dist'])
                    bestNbr = currentSolution
                    bestDist = self.totalDist(self.groupMetrics(currentSolution,aggMethod),distMetric)
                    
                    #make a list of nbr distances
                    for i in self.createNbrhood(currentSolution,self.nbrhoodsize):
                        obs = obs + 1
                        
                        temp_nbr_df = temp_nbr_df.append({'nbr':i,'dist':self.totalDist(self.groupMetrics(i,aggMethod),distMetric)},ignore_index=True)
                        
                    
                    
                    #if none of the new neighbors are better than current solution, stop
                    dists = temp_nbr_df['dist']
                    
                    if min(dists) > bestDist:
                        done = 1
                        break
                
                    temp_nbr_df = temp_nbr_df.sort_values(by='dist')
                    
                    #reset index to be able to point to new positions after sorting
                    temp_nbr_df = temp_nbr_df.reset_index()
                    
                    temp_array = temp_nbr_df['dist'].values
                    
                    temp_array = np.power(temp_array,power)
                    
                    #flip array so lowest values have highest probability of selection
                    temp_array = np.flip(temp_array)
                    
                    temp_array_sum = np.sum(temp_array)
                    
                    temp_array = temp_array/temp_array_sum
                    
                    #create cumulative array to go into rand_find function
                    temp_array_cum = np.cumsum(temp_array)
                    
                    
                    #find index of randomly selected nbr
                    index_num = rand_find(temp_array_cum,random.uniform(0,1))
                    
                    bestNbr = temp_nbr_df['nbr'][index_num]
                    bestDist = self.totalDist(self.groupMetrics(bestNbr,aggMethod),distMetric)
                    currentSolution = bestNbr 
                    
                    print(bestDist)
                        
                        
                print("restart")
                
                if bestDist < globalBestDist:
                    globalBestNbr = bestNbr
                    globalBestDist = self.totalDist(self.groupMetrics(bestNbr,aggMethod),distMetric)
                    print("New Global Best = %s" % globalBestDist)
                    
                    
            #put the globals back into the locals so the return statement returns the global bests
            #bestNbr = globalBestNbr
            #bestDist = globalBestDist
            
            print("done")  
                    
                
        obs_statement = ("%s Solutions Examined" % obs)
    
        #return solution metric and solution
        return [self.groupMetrics(globalBestNbr,aggMethod),globalBestNbr,globalBestDist,obs_statement]
    
    #when a new global minimum is found, expand search to 2 swap, maybe even 3 swap?
    def runVNS(self,VNS_type,restarts,aggMethod,distMetric,startMetric=1,randStart='Y',expandFactor=2,nSwaps=2):
        
        #VNS_type has 3 options -- EXPAND, 2SWAP, 3SWAP. EXPAND increases nbrhood size by a specified factor when a minimum is found,
                                   #2SWAP changes nbrhood to 2 swap when min is found
                                   #3SWAP changes nbrhood to 3 swap when min is found
        
        obs = 0
        
        startSolution = self.startSol(randStart=randStart,startMetric=startMetric)
        
        #conditionally execute hill climb with EXPAND
        if VNS_type == 'EXPAND':
        
            globalBestNbr = startSolution
            globalBestDist = self.totalDist(self.groupMetrics(startSolution,aggMethod),distMetric)
            
            for j in range(0,restarts):
                
            
                #do a random start if it is not the first iteration
                if j == 0:
                    currentSolution = startSolution
                else:
                    currentSolution = self.startSol(randStart=randStart,startMetric=startMetric)
            
                done = 0
            
                while done == 0:
                    
                    bestNbr = currentSolution
                    bestDist = self.totalDist(self.groupMetrics(currentSolution,aggMethod),distMetric)
                    
                    for i in self.createNbrhood(currentSolution,self.nbrhoodsize):
                        obs = obs + 1
                        if self.totalDist(self.groupMetrics(i,aggMethod),distMetric) < self.totalDist(self.groupMetrics(bestNbr,aggMethod),distMetric):
                            bestNbr = i
                            bestDist = self.totalDist(self.groupMetrics(i,aggMethod),distMetric)
                            print(bestDist)
                            
                    if currentSolution == bestNbr:
                        done = 1
                    else:
                        currentSolution = bestNbr 
                        
                        
                print("restart")
                
                if bestDist < globalBestDist:
                    globalBestNbr = bestNbr
                    globalBestDist = self.totalDist(self.groupMetrics(bestNbr,aggMethod),distMetric)
                    print("New Global Best = %s" % globalBestDist)
                    print("Start Expanded Search")
                    
                    best_nbr = 0
                
                    while best_nbr == 0:
                        
                        bestNbr = currentSolution
                        bestDist = self.totalDist(self.groupMetrics(currentSolution,aggMethod),distMetric)
                        
                        for i in self.createNbrhood(currentSolution,int(round(self.nbrhoodsize*expandFactor,0))):
                            obs = obs + 1
                            if self.totalDist(self.groupMetrics(i,aggMethod),distMetric) < self.totalDist(self.groupMetrics(bestNbr,aggMethod),distMetric):
                                bestNbr = i
                                bestDist = self.totalDist(self.groupMetrics(i,aggMethod),distMetric)
                                
                                
                                
                        if currentSolution == bestNbr:
                            best_nbr = 1
                            globalBestNbr = bestNbr
                            print("Global Best = %s" % globalBestDist)                            
                        else:
                            currentSolution = bestNbr       
                    print("End expanded search")
                
                obs_statement = ("%s Solutions Examined" % obs)
                print("done")                       
                    
                    
            
        #conditionally execute hill climb with EXPAND
        elif VNS_type == 'NSWAP':
            
            globalBestNbr = startSolution
            globalBestDist = self.totalDist(self.groupMetrics(startSolution,aggMethod),distMetric)
                
            for j in range(0,restarts):
                    
                
                #do a random start if it is not the first iteration
                if j == 0:
                    currentSolution = startSolution
                else:
                    currentSolution = self.startSol(randStart=randStart,startMetric=startMetric)
                
                done = 0
                
                while done == 0:
                        
                    bestNbr = currentSolution
                    bestDist = self.totalDist(self.groupMetrics(currentSolution,aggMethod),distMetric)
                        
                    for i in self.createNbrhood(currentSolution,self.nbrhoodsize):
                        obs = obs + 1
                        if self.totalDist(self.groupMetrics(i,aggMethod),distMetric) < self.totalDist(self.groupMetrics(bestNbr,aggMethod),distMetric):
                            bestNbr = i
                            bestDist = self.totalDist(self.groupMetrics(i,aggMethod),distMetric)
                            print(bestDist)
                                
                    if currentSolution == bestNbr:
                        done = 1
                    else:
                        currentSolution = bestNbr 
                            
                            
                print("restart")
                    
                if bestDist < globalBestDist:
                    globalBestNbr = bestNbr
                    globalBestDist = self.totalDist(self.groupMetrics(bestNbr,aggMethod),distMetric)
                    print("New Global Best = %s" % globalBestDist)
                    print("Start %s Swap Search" % nSwaps)
                        
                    best_nbr = 0
                    
                    while best_nbr == 0:
                            
                        bestNbr = currentSolution
                        bestDist = self.totalDist(self.groupMetrics(currentSolution,aggMethod),distMetric)
                            
                        for i in self.createNbrhood(currentSolution,self.nbrhoodsize,numSwaps=nSwaps):
                            obs = obs + 1
                            if self.totalDist(self.groupMetrics(i,aggMethod),distMetric) < self.totalDist(self.groupMetrics(bestNbr,aggMethod),distMetric):
                                bestNbr = i
                                bestDist = self.totalDist(self.groupMetrics(i,aggMethod),distMetric)
                                    
                                    
                                    
                        if currentSolution == bestNbr:
                            best_nbr = 1
                            globalBestNbr = bestNbr
                            print("Global Best = %s" % globalBestDist)                            
                        else:
                            currentSolution = bestNbr       
                    print("End expanded search")
                        
                        
                    
            obs_statement = ("%s Solutions Examined" % obs)
            print("done")              
            
        #return solution metric and solution
        return [self.groupMetrics(globalBestNbr,aggMethod),globalBestNbr,globalBestDist,obs_statement]            
        
        
        
        
        
        
        
    #Inherits baseHueristic class
    #Provides random neighborhood start, and neighborhood creation based on current solution space
    #Does not provide any kind of decisions based on neighborhoods => use specific heuristic classes for those methods
import base_class as bc
import random
import copy

class nbrHood(bc.baseHeuristic):
    #nbrHoodSize = the number of nbrs that will be explored
    #numGroups = the number of groups that the hueristic will put the elements into
    #numSwaps = how many swaps to get neighbors
    #startMetric = the column number of the dataframe that will be used to estimate a good starting point ==> defaults to 1
    #extraSwapProb = probability of switching 2 elements for one.  This allows the number of elements in the groups to migrate,
    #  If this is 0, the groups will have the same number of elements as the starting solution. This will confine the search
    #groupsSize = a list that has number of elements equal to numGroups. This forces each group to have a specified number 
    #  of elements
    #elemSum = limits the number of elements used in all three groups. If used only wants 20 elements to be used among 3
    #  groups, numGroups = 3, elemSum = 20. This does not constrain how many elements are in each group, use groupSize
    #  to control number elements in each group
    #seed = any arbitrary number used to get random numbers
    #randStart = User decide to use random start or deterministic start based on a specific column. Acceptable values are 'Y'
    #  and 'N'
    
    #I think I'm not going to do anything with groupSize or elemSum right now.  Maybe an add on for a future version
    
    def __init__(self,df,numGroups):
        
        super().__init__(df)
        #user defined attributes
        self.numGroups = numGroups

    
    #give user ability to update numGroups w/o having to create a new class
    def setNumGroups(self,numGroups):
        self.numGroups = numGroups
        
    #method to create a starting solution
    def startSol(self,randStart='Y',startMetric=1,seed=1920):
        
        #conditionally create a random or deterministic starting solution
        if randStart == 'Y':
            
            #set random seed
            #random.seed(seed)
            
            #create label list to hold all lables 
            label_list = list(self.df.iloc[:,0])
            
            #instantiate grouping list
            grouping = []

            #initiate first element in each group
            for i in range(0,self.numGroups):
                rand_num = random.randint(0,len(label_list)-1)
                grouping.append([label_list[rand_num]])
                label_list.pop(rand_num)
                
            #loop through each group and add a random element to it until no more elements are left
            while len(label_list) > 1:
                for j in range(0,self.numGroups):
                    #exit loop if label_list becomes too short to avoid out of range errors generated by rand_num
                    if len(label_list) == 1:
                        break
                    rand_num = random.randint(0,len(label_list)-1)
                    grouping[j].append(label_list[rand_num])
                    label_list.pop(rand_num)
                    temp_j = j
            
            #put the last remaining value to the grouping
            grouping[temp_j + 1].append(label_list[0])
                    
                             
        #if not a random starting place, 
        elif randStart == 'N':
            #sort dataframe by startMetric column
            sorted_df = self.df.sort_values(self.startMetric)

            #convert label column in df to list to access .pop() method
            label_list = list(sorted_df.iloc[:,0])
            
            
            #put each element recursively in a group
            grouping = []
            #manually do first iteration to instantiate the appropriate sized list
            for h in range(0,self.numGroups):
                grouping.append([label_list[h]])
            
            #remove elements that were added to grouping in the previous loop
            label_list = label_list[self.numGroups:len(label_list)]

                
            #now that the grouping list is instantiated w/ approprate dimensions, put the rest of the elements into groups
            switch_dir = 1
            
            while len(label_list) > 0:
                if switch_dir == 0:
                
                    #create a varable for looping based on length of lable_list and self.numGroups
                    if len(label_list) < self.numGroups:
                        loop_count = len(label_list)
                    else:
                        loop_count = self.numGroups
                    
                    
                    for i in range(0,loop_count):
                        
                        grouping[i].append(label_list[i])
                        
                    #remove all elements that were just added to the grouping list
                    label_list = label_list[loop_count:len(label_list)]
                            
                    #set switch_dir to 1, so it will loop the opposite direction next while iteration
                    switch_dir = 1
                    print(grouping)
                    
                elif switch_dir == 1:

                    
                    for j in range(self.numGroups-1,-1,-1):
                        print(j)
                        
                        #exit loops if label_list is empty
                        if len(label_list) == 0:
                            break
                            
                        grouping[j].append(label_list[0])
                        label_list.pop(0)
                    
                    
                    #set switch_dir to 0, so it will loop the opposite direction next while iteration
                    switch_dir = 0
                    print(grouping)
                    
        return grouping
    
    
    #create a nieghborhood based on swapping
    #groups input is the solution that needs neighbors
    def createSeqList(self,start,stop):
        
            return_list = []
        
        
            for i in range(start,stop):
                return_list.append(i)
    
        
            return return_list
        
        
            
        
    def createNbrhood(self,groups,nbrHoodSize,numSwaps=1,extraSwapProb=0.1,seed=1920):
         
            swap_record = []
            nbrHood = []
            
            for i in range(0,nbrHoodSize):
            #for i in range(0,len(nbrHoodSize)):
        
                #calculate probability for a random extra swap
                extraSwapRand = random.uniform(0,1)
        
        
        
                #select two groups
                groups_copy = copy.deepcopy(groups)
                group_copy = list(range(0,len(groups)))
        
        
                group1 = random.randint(0,len(groups)-1)
                group_copy.pop(group1)
        
                group2 = random.choice(group_copy)
        
        
                    #select an element from each group to swap
        
                for j in range(0,numSwaps):
        

                    group1_list = self.createSeqList(0,len(groups_copy[group1]))    
                    group2_list = self.createSeqList(0,len(groups_copy[group2]))
        
                    swap1 = random.choice(group1_list)
                    swap2 = random.choice(group2_list)
        
               
                    if extraSwapRand < extraSwapProb and j == 0:
        
                        #perform swap and save new neighbor in neighbor list
                        swap_val1 = groups_copy[group1][swap1]      
                        swap_val2 = groups_copy[group2][swap2]
        
    
                        groups_copy[group1][swap1] = swap_val2       
                        groups_copy[group2][swap2] = swap_val1
        
              
                        group1_list.remove(swap1)
                        group2_list.remove(swap2)
        
       
                        #add extra element swap after the initial swap      
                        swap3 = random.choice(group2_list)
                        swap_val3 = groups_copy[group2][swap3]
        
                        groups_copy[group1].append(swap_val3)
                        groups_copy[group2].pop(swap3)
        
                        group2_list.remove(swap3)
        
        
                    else:
        
                        swap_val1 = groups_copy[group1][swap1]
                        swap_val2 = groups_copy[group2][swap2]
        
        
                        groups_copy[group1][swap1] = swap_val2
                        groups_copy[group2][swap2] = swap_val1
             
                        group1_list.remove(swap1)    
                        group2_list.remove(swap2)
          
        
                #put neighbor into neighborhood list
        
                nbrHood.append(groups_copy)
   
            return nbrHood
        
import nbr_hood as nbr
import random
import pandas as pd
import numpy as np
from math import exp


#create class for hill climb algorithms
class simulatedAnnealing(nbr.nbrHood):
    
    def __init__(self,df,numGroups,nbrhoodsize):
        
        super().__init__(df,numGroups)
        self.nbrhoodsize = nbrhoodsize
    
    def runSimulatedAnnealing(self,restarts,coolingSchedule,tempIters,aggMethod,distMetric,randStart='Y',startMetric=1):
        
        #random.seed(seed)
        obs = 0
    
        #create a starting solution
        startSolution = self.startSol(randStart=randStart,startMetric=startMetric)        
        
        currentSolution = startSolution
        currentDist = self.totalDist(self.groupMetrics(startSolution,aggMethod),distMetric)
            
        for temperature in coolingSchedule:
                
            print('temparature is %s' % temperature)
                
            for iters in range(0,tempIters):
                              
                temp_nbr = self.createNbrhood(currentSolution,2)
                
                        
                obs = obs + 1
                       
                        
                #calculate difference between current nbr and the best nbr
                delta = self.totalDist(self.groupMetrics(temp_nbr[0],aggMethod),distMetric) - self.totalDist(self.groupMetrics(currentSolution,aggMethod),distMetric)
                    
                #calculate acceptance probability
                if delta < 0:
                    acceptProb = 1.1
                else:
                    acceptProb = exp(-delta/temperature)
                        
                #decide if it will be accepted 
                if acceptProb > random.uniform(0,1):
                    currentSolution = temp_nbr[0]
                    currentDist = self.totalDist(self.groupMetrics(currentSolution,aggMethod),distMetric)
                    print(currentDist)
                    
                    
            obs_statement = ("%s Solutions Examined" % obs)
            print("done")              
            
        #return solution metric and solution
        return [self.groupMetrics(currentSolution,aggMethod),currentSolution,currentDist,obs_statement]     
    
    
import nbr_hood as nbr
import random
import pandas as pd
import numpy as np

            
class tabuSearch(nbr.nbrHood):
    
    def __init__(self,df,numGroups,nbrhoodsize):
        
        super().__init__(df,numGroups)
        self.nbrhoodsize = nbrhoodsize
        
        
    def tabu(self,iters,tenure,startMetric=1,randStart='Y',aggMethod='avg',distMetric='euc'):
        
        #create simple function to get the difference in lists
        def listDiff(a, b): 
            return (list(set(a) - set(b)))           
        
        #create a starting solution
        startSolution = self.startSol(randStart=randStart,startMetric=startMetric)  
        
        globalBestNbr = startSolution
        globalBestDist = self.totalDist(self.groupMetrics(startSolution,aggMethod),distMetric)        
        
        
        obs = 0
        
        for h in range(0,iters):
    
            currentSolution = startSolution
            
            tabu_memory = []
    
            done = 0   
            
            while done == 0:
                
               
                    
                bestNbr = currentSolution
                bestDist = self.totalDist(self.groupMetrics(currentSolution,aggMethod),distMetric)
                
                #manage tabu search memory. For double swaps, some things will get deleted with the same tenure. 
                for i in tabu_memory:
                    while len(tabu_memory) > tenure:
                        #delete first element
                        i.pop(0)
                
                #remove tabu elements before creating nbrs (this prevents them from being swapped)
                pos = -1
                for j in tabu_memory:
                    pos= pos + 1
                    for k in j:
                        bestNbr[pos].remove(k)
                        
                        
                #create nbrhood to iterate through (iterate through the nbrs of the nbrhood)  
                for i in self.createNbrhood(currentSolution,self.nbrhoodsize):
                    obs = obs + 1
                    
                    #re-add tabu before distance measurements
                    
                    #re-add tabu to bestNbr
                    pos = -1
                    for j in tabu_memory:
                        pos = pos + 1
                        for k in j:
                            bestNbr[pos].append(k)
                            
                    
                    
                    #re-add tabu to current neighbor being evaluated
                    pos = -1
                    for j in tabu_memory:
                        pos = pos + 1
                        for k in j:
                            i[pos].append(k)
                            
                    
                    if self.totalDist(self.groupMetrics(i,aggMethod),distMetric) < self.totalDist(self.groupMetrics(bestNbr,aggMethod),distMetric):
                        bestNbr = i
                        bestDist = self.totalDist(self.groupMetrics(i,aggMethod),distMetric)
                        print(bestDist)
                            
                if currentSolution == bestNbr:
                    done = 1
                else:
                    #find difference between currentSolution and bestNbr. Add that to end of tabu list
                    for i in tabu_memory:
                        i.append(listDiff(bestNbr[i],currentSolution[i]))
                                                       
                    currentSolution = bestNbr
                    
                    print("restart")
                    
                if bestDist < globalBestDist:
                    globalBestNbr = bestNbr
                    globalBestDist = self.totalDist(self.groupMetrics(bestNbr,aggMethod),distMetric)
                    print("New Global Best = %s" % globalBestDist)                    
                    
                obs_statement = ("%s Solutions Examined" % obs)          
                
        #return solution metric and solution
        return [self.groupMetrics(globalBestNbr,aggMethod),globalBestNbr,globalBestDist,obs_statement]            
                            
                    
                            
#---------------------------------------------------------------------------------------------------------------------------------------------------
#---------------------------------------------------------------------------------------------------------------------------------------------------
#---------------------------------------------------------------------------------------------------------------------------------------------------
#---------------------------------------------------------------------------------------------------------------------------------------------------


#Run all scripts for project

#import data
test_df = pd.read_csv("/home/ec2-user/state_data.csv")

#-----------------------------------------------------------------------------------------------------------------------------
#hill climb -- Best Accept
#first is nbrhood size, second is restarts
execution = [[10,50,'BA_10_50.csv'],[15,50,'BA_15_50.csv'],[20,50,'BA_20_50.csv'],[25,50,'BA_25_50.csv'],[30,50,'BA_30_50.csv'],[35,50,'BA_35_50.csv'],[50,50,'BA_50_50.csv']
            ,[100,50,'BA_100_50.csv'],[150,10,'BA_150_10.csv'],[170,10,'BA_170_10.csv'],[190,10,'BA_190_10.csv'],[210,10,'BA_210_10.csv'],[250,10,'BA_250_10.csv']]

for i in execution:
    
    print("Running %s nbrs with %s restarts" % (i[0],i[1]))
    
    #create instance of hillClimb
    test = hillClimb(test_df,numGroups=3,nbrhoodsize=i[0]) 
    
    results = test.runHillClimb(selectMethod='BEST ACCEPT',aggMethod='avg',distMetric='euc',restarts=i[1])
    
    group1 = results[1][0]
        
    group2 = results[1][1]
    
    group3 = results[1][2]
    
    dist = results[2]
    
    obs_statement = results[3]
    
    results_list = [group1,group2,group3,[dist],[obs_statement]]
    
    results_df = pd.DataFrame(results_list)
    
    
    results_df.to_csv("/home/ec2-user/"+i[2])


#------------------------------------------------------------------------------------------------------------------------------------------
#hill climb -- First Accept
#first is nbrhood size, second is restarts
execution = [ [10,50,'FA_10_50.csv'],[15,50,'FA_15_50.csv'],[20,50,'FA_20_50.csv'],[25,50,'FA_25_50.csv'],[30,50,'FA_30_50.csv'],[35,50,'FA_35_50.csv'],[50,50,'FA_50_50.csv']
             ,[100,50,'FA_100_50.csv'],[150,10,'FA_150_10.csv'],[170,10,'FA_170_10.csv'],[190,10,'FA_190_10.csv'],[210,10,'FA_210_10.csv'],[250,10,'FA_250_10.csv']]

for i in execution:
    
    print("Running %s nbrs with %s restarts" % (i[0],i[1]))
    
    #create instance of hillClimb
    test = hillClimb(test_df,numGroups=3,nbrhoodsize=i[0]) 
    
    results = test.runHillClimb(selectMethod='FIRST ACCEPT',aggMethod='avg',distMetric='euc',restarts=i[1])
    
    group1 = results[1][0]
        
    group2 = results[1][1]
    
    group3 = results[1][2]
    
    dist = results[2]
    
    obs_statement = results[3]
    
    results_list = [group1,group2,group3,[dist],[obs_statement]]
    
    results_df = pd.DataFrame(results_list)
    
    
    results_df.to_csv("/home/ec2-user/"+i[2])



#--------------------------------------------------------------------------------------------------------------------
#hill climb -- Random Walk
execution = [[150,10,1,'RW_150_10_1.csv'],[170,10,1,'RW_170_10_1.csv'],[190,10,1,'RW_190_10_1.csv'],[210,10,1,'RW_210_10_1.csv'],[250,10,1,'RW_250_10_1.csv']
            ,[150,10,2,'RW_150_10_2.csv'],[170,10,2,'RW_170_10_2.csv'],[190,10,2,'RW_190_10_2.csv'],[210,10,2,'RW_210_10_2.csv'],[250,10,2,'RW_250_10_2.csv']
            ,[150,10,3,'RW_150_10_3.csv'],[170,10,3,'RW_170_10_3.csv'],[190,10,3,'RW_190_10_3.csv'],[210,10,3,'RW_210_10_3.csv'],[250,10,3,'RW_250_10_3.csv']]

for i in execution:


    #create instance of hillClimb
    test = hillClimb(test_df,numGroups=3,nbrhoodsize=i[0]) 

    #need to increase power, otherwise this will run forever

    results = test.runHillClimb(selectMethod='RANDOM WALK',aggMethod='avg',distMetric='euc',restarts=i[1],power=i[2])

    group1 = results[1][0]

    group2 = results[1][1]

    group3 = results[1][2]

    dist = results[2]

    obs_statement = results[3]

    results_list = [group1,group2,group3,[dist],[obs_statement]]

    results_df = pd.DataFrame(results_list)


    results_df.to_csv("/home/ec2-user/"+i[3])


#-------------------------------------------------------------------------------------------------------
#VNS

#VNS EXPAND
execution = [ [150,10,2,'VNS_E_150_10_2.csv'],[170,10,2,'VNS_E_170_10_2.csv'],[190,10,2,'VNS_E_190_10_2.csv'],[210,10,2,'VNS_E_210_10_2.csv'],[250,10,2,'VNS_E_250_10_2.csv']
             ,[150,10,3,'VNS_E_150_10_3.csv'],[170,10,3,'VNS_E_170_10_3.csv'],[190,10,3,'VNS_E_190_10_3.csv'],[210,10,3,'VNS_E_210_10_3.csv'],[250,10,3,'VNS_E_250_10_3.csv']
             ,[150,10,4,'VNS_E_150_10_4.csv'],[170,10,4,'VNS_E_170_10_4.csv'],[190,10,4,'VNS_E_190_10_4.csv'],[210,10,4,'VNS_E_210_10_4.csv'],[250,10,4,'VNS_E_250_10_4.csv']]

for i in execution:

    print("Running %s nbrs with %s iterations" % (i[0],i[1]))

    #create instance of hillClimb
    test = hillClimb(test_df,numGroups=3,nbrhoodsize=i[0]) 

    results = test.runVNS(VNS_type='EXPAND',restarts=i[2],aggMethod='avg',distMetric='euc',nSwaps=i[1])

    group1 = results[1][0]

    group2 = results[1][1]

    group3 = results[1][2]

    dist = results[2]

    obs_statement = results[3]

    results_list = [group1,group2,group3,[dist],[obs_statement]]

    results_df = pd.DataFrame(results_list)

    results_df.to_csv("/home/ec2-user/"+i[3])   


#--------------------------------------------------------------------------------------------------------------------------------------------    
#VNS SWAP
execution = [ [150,10,2,'VNS_S_150_10_2.csv'],[170,10,2,'VNS_S_170_10_2.csv'],[190,10,2,'VNS_S_190_10_2.csv'],[210,10,2,'VNS_S_210_10_2.csv'],[250,10,2,'VNS_S_250_10_2.csv']
             ,[150,10,3,'VNS_S_150_10_3.csv'],[170,10,3,'VNS_S_170_10_3.csv'],[190,10,3,'VNS_S_190_10_3.csv'],[210,10,3,'VNS_S_210_10_3.csv'],[250,10,3,'VNS_S_250_10_3.csv']
             ,[150,10,4,'VNS_S_150_10_4.csv'],[170,10,4,'VNS_S_170_10_4.csv'],[190,10,4,'VNS_S_190_10_4.csv'],[210,10,4,'VNS_S_210_10_4.csv'],[250,10,4,'VNS_S_250_10_4.csv']]

for i in execution:

    print("Running %s nbrs with %s restarts" % (i[0],i[1]))

    #create instance of hillClimb
    test = hillClimb(test_df,numGroups=3,nbrhoodsize=i[0]) 

    results = test.runVNS(VNS_type='NSWAP',restarts=i[2],aggMethod='avg',distMetric='euc',nSwaps=i[1])

    group1 = results[1][0]

    group2 = results[1][1]

    group3 = results[1][2]

    dist = results[2]

    obs_statement = results[3]

    results_list = [group1,group2,group3,[dist],[obs_statement]]

    results_df = pd.DataFrame(results_list)


    results_df.to_csv("/home/ec2-user/"+i[3])

#-----------------------------------------------------------------------------
#Tabu 

#first is nbrhood size, second is restarts
execution = [ [150,10,2,'TABU_150_10_2.csv'],[170,10,2,'TABU_170_10_2.csv'],[190,10,2,'TABU_190_10_2.csv'],[210,10,2,'TABU_210_10_2.csv'],[250,10,2,'TABU_250_10_2.csv']
             ,[150,10,3,'TABU_150_10_3.csv'],[170,10,3,'TABU_170_10_3.csv'],[190,10,3,'TABU_190_10_3.csv'],[210,10,3,'TABU_210_10_3.csv'],[250,10,3,'TABU_250_10_3.csv']
             ,[150,10,4,'TABU_150_10_4.csv'],[170,10,4,'TABU_170_10_4.csv'],[190,10,4,'TABU_190_10_4.csv'],[210,10,4,'TABU_210_10_4.csv'],[250,10,4,'TABU_250_10_4.csv']
             ,[150,10,5,'TABU_150_10_5.csv'],[170,10,5,'TABU_170_10_5.csv'],[190,10,5,'TABU_190_10_5.csv'],[210,10,5,'TABU_210_10_5.csv'],[250,10,5,'TABU_250_10_5.csv']]

for i in execution:

    print("Running %s nbrs with %s restarts" % (i[0],i[1]))

    #create instance of hillClimb
    test = tabuSearch(test_df,numGroups=3,nbrhoodsize=i[0]) 

    #tabu(self,iters,tenure,startMetric=1,randStart='Y',aggMethod='avg',distMetric='euc'):

    results = test.tabu(iters=i[1],tenure=i[2],aggMethod='avg',distMetric='euc')

    group1 = results[1][0]

    group2 = results[1][1]

    group3 = results[1][2]

    dist = results[2]

    obs_statement = results[3]

    results_list = [group1,group2,group3,[dist],[obs_statement]]

    results_df = pd.DataFrame(results_list)


    results_df.to_csv("/home/ec2-user/"+i[3])
    
    
 

#---------------------------------------------------------------------------------------------------------------------------------
#Simulated Annealing

#first is nbrhood size, second is restarts
cooling_sched1 = [0.15,0.125,0.1,0.075,0.05,0.025,0.01]
cooling_sched2 = [0.15,0.14,0.13,0.12,0.11,0.10,0.09,0.08,0.07,0.06,0.05,0.04,0.03,0.02,0.01]

execution = [[10,cooling_sched1,100,'SA_100_sched1.csv'],[10,cooling_sched1,150,'SA_150_sched1.csv'],[10,cooling_sched1,200,'SA_200_sched1.csv'],[10,cooling_sched1,250,'SA_250_sched1.csv']
            ,[10,cooling_sched2,100,'SA_100_sched2.csv'],[10,cooling_sched2,150,'SA_150_sched2.csv'],[10,cooling_sched2,200,'SA_200_sched2.csv'],[10,cooling_sched2,250,'SA_250_sched2.csv']]

for i in execution:

    print("Running %s iterations at temperature" % (i[2]))

    #create instance of hillClimb
    test = simulatedAnnealing(test_df,numGroups=3,nbrhoodsize=i[0]) 

    results = test.runSimulatedAnnealing(tempIters=i[2],coolingSchedule=i[1],aggMethod='avg',distMetric='euc')

    group1 = results[1][0]

    group2 = results[1][1]

    group3 = results[1][2]

    dist = results[2]

    obs_statement = results[3]

    results_list = [group1,group2,group3,[dist],[obs_statement]]

    results_df = pd.DataFrame(results_list)


    results_df.to_csv("/home/ec2-user/"+i[3])
